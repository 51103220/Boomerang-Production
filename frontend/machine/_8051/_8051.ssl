MAX8BITS := 0xFF;

ADDRESSBITS := 8;

INTEGER
[%r0, %r1, %r2, %r3, %r4, %r5, %r6, %r7 ][8] -> 0..7,
%a[8] -> 8,
%b[8] -> 9,
%c[8] -> 10,
[%dptr][16] -> 11,#0..15
[  %ab, %p0, %p1, %p2 , %p3, 
  %dpl, %dph, %pcon, %tcon, 
  %tmod, %tl0, %tl1, %th0, %th1, 
  %scon, %sbuf, %ie, %ip, %psw ][8] -> 12..30, #sfr 
[%CF, %AC, %OV][1] -> -1,  # Standard flags
[%pc][32] -> -1,
%sp[32] -> 88;

add_signed_pc(param) {
  *32* tmp5 := %pc + param
  *32* tmp5 := [param < 128 ? tmp5 : tmp5 - 256]
};

# 0x00
NOP
  _;

AJMP_IMM i32
  *32* %pc := i32;

LJMP_ADDR16 i32
  *32* %pc := i32;

RR_A exp
  *1* tmpb := exp@[7:7]
  *7* exp@[1:7] := exp@[0:6]
  *1* exp@[0:0] := tmpb;

INC_DIR z32
  *8* m[z32] := m[z32]{8} + 1;

INC_A
  *8* %a := %a + 1;

INC_R0
  *8* %r0 := %r0 + 1;

INC_R1
  *8* %r1 := %r1 + 1;

INC_R2
  *8* %r2 := %r2 + 1;

INC_R3
  *8* %r3 := %r3 + 1;

INC_R4
  *8* %r4 := %r4 + 1;

INC_R5
  *8* %r5 := %r5 + 1;

INC_R6
  *8* %r6 := %r6 + 1;

INC_R7
  *8* %r7 := %r7 + 1;

INC_EXP exp
  *8* exp := exp + 1;

INC_EXP_EXP exp1,exp2
  *8* exp1 := exp2 + 1;

INC_RI0
  *32* tmp1 := zfill(8, 31, %r0)
  *8* tmpb := m[tmp1]{8}
  *8* tmpb := tmpb + 1
  *8* m[tmp1] := tmpb;

INC_RI1
  *32* tmp1 := zfill(8, 31, %r1)
  *8* tmpb := m[tmp1]{8}
  *8* tmpb := tmpb + 1
  *8* m[tmp1] := tmpb;

# 0x10

JBC_DIR_IMM  z32, i32
  *32* %pc := %pc + 3
  *8* tmpb := m[z32]{8}
  add_signed_pc(i32)
  *8* m[z32] := 0
  *32* %pc := [tmpb = 1 ? %pc : tmp5];

# ACALL
ACALL_IMM i32
  *32* %pc := %pc + 2
  *32* %sp := %pc
  *32* %pc := i32;

# LCALL
LCALL_ADDR16 i32
  *32* %pc := %pc + 2
  *32* %sp := %sp + 1
  *32* m[%sp] := %pc
  *32* %pc := i32;

RRC_A exp
  *1* tmpb := %c
  *1* %c := exp@[0:0]
  *7* exp@[1:7] := exp@[0:6]
  *1* bt := exp@[7:7]
  *1* bt := tmpb;

DEC_EXP exp
  *8* exp := exp - 1;

DEC_EXP_EXP exp1, exp2
  *8* exp1 := exp2 - 1;

DEC_DIR  z32
  *8* m[z32] := m[z32]{8} - 1;

DEC_A
  *8* %a := %a - 1;

DEC_R0
  *8* %r0 := %r0 - 1;

DEC_R1
  *8* %r1 := %r1 - 1;

DEC_R2
  *8* %r2 := %r2 - 1;

DEC_R3
  *8* %r3 := %r3 - 1;

DEC_R4
  *8* %r4 := %r4 - 1;

DEC_R5
  *8* %r5 := %r5 - 1;

DEC_R6
  *8* %r6 := %r6 - 1;

DEC_R7
  *8* %r7 := %r7 - 1;

DEC_RI0
  *32* tmp1 := zfill(8, 31, %r0)
  *8* tmpb := m[tmp1]{8}
  *8* tmpb := tmpb - 1
  *8* m[tmp1] := tmpb;

DEC_RI1
  *32* tmp1 := zfill(8, 31, %r1)
  *8* tmpb := m[tmp1]{8}
  *8* tmpb := tmpb - 1
  *8* m[tmp1] := tmpb;

# 0x20

JB_DIR_IMM  z32, i32
  #*32* %pc := %pc +3
  #add_signed_pc(i32)
  #*1* %CF := [m[z32]{8}=1? 1 : 0];
  *v* %flags := z32{8}  ~= 1;


AJMP_IMM i32
  *32* %pc := i32;

RET retaddr
  *32* retaddr := %sp
  *32* %pc := retaddr;

RL_A exp
  *1* tmpb := exp@[0:0]
  *7* exp@[0:6] := exp@[1:7]
  *1* exp@[7:7] := tmpb;


ADD_A_IMM exp,i32
  *8* exp := exp + i32;

ADD_A_DIR  exp,z32
  *8* exp := exp + m[z32]{8};

ADD_A_RI0 exp
  *32* tmp1 := zfill(8, 31, %r0)
  *8* tmpb := m[tmp1]{8}
  *8* exp := exp + m[tmp1];

ADD_A_RI1 exp
  *32* tmp1 := zfill(8, 31, %r1)
  *8* tmpb := m[tmp1]{8}
  *8* exp := exp + m[tmp1];

ADD_A_EXP exp1, exp2
  *8* exp1 := exp1 + exp2;

ADD_A_R0
  *8* %a := %a + %r0;

ADD_A_R1
  *8* %a := %a + %r1;

ADD_A_R2
  *8* %a := %a + %r2;

ADD_A_R3
  *8* %a := %a + %r3;

ADD_A_R4
  *8* %a := %a + %r4;

ADD_A_R5
  *8* %a := %a + %r5;

ADD_A_R6
  *8* %a := %a + %r6;

ADD_A_R7
  *8* %a := %a + %r7;

# 0x30

JNB_DIR_IMM  z32, i32
  #*32* %pc := %pc +3
  #add_signed_pc(i32)
  #*32* %pc := [m[z32]=0? tmp5 : %pc];
  *v* %flags := z32{8}  ~= 0;
# ACALL

RETI retaddr
  *32* retaddr := m[%sp]{32}
  *32* %pc := retaddr;

RLC_A exp
  *1* tmpb := %c
  *1* %c := exp@[0:0]
  *7* exp@[0:6] := exp@[1:7]
  *1* bt := exp@[7:7]
  *1* bt := tmpb;

ADDC_A_IMM i32
  *8* %a := %a + i32@[0:7];

ADDC_A_DIR  z32
  *8* %a := %a + m[z32]{8};

ADDC_A_RI0 exp1, exp2
  *32* tmp1 := zfill(8, 31, %r0)
  *8* tmpb := m[tmp1]{8}
  *8* exp1 := exp1 + exp2 + m[tmp1];

ADDC_A_RI1 exp1, exp2
  *32* tmp1 := zfill(8, 31, %r1)
  *8* tmpb := m[tmp1]{8}
  *8* exp1 := exp1 + exp2 + m[tmp1];

ADDC_A_EXP exp1, exp2,exp3
  *8*  exp1 := exp1 + exp2 + exp3;

ADDC_A_R0
  *8* %a := %a + %r0;

ADDC_A_R1
  *8* %a := %a + %r1;

ADDC_A_R2
  *8* %a := %a + %r2;

ADDC_A_R3
  *8* %a := %a + %r3;

ADDC_A_R4
  *8* %a := %a + %r4;

ADDC_A_R5
  *8* %a := %a + %r5;

ADDC_A_R6
  *8* %a := %a + %r6;

ADDC_A_R7
  *8* %a := %a + %r7;

# 0x40

JC_IMM exp
  #*32* %pc := %pc + 2
  #add_signed_pc(i32)
  #*32* %pc := [%CF = 1 ? tmp5: %pc];
  *v* %flags := exp ~= 1; 

#### BITWISE #####
ORL_EXP exp1, exp2
  *8* exp1 := exp1 | exp2;

ANL_EXP exp1, exp2
  *8* exp1 := exp1 & exp2;

XRL_EXP exp1, exp2
  *8* exp1 := exp1 ^ exp2;

ORL_EXP_RI0 exp
  *32* tmp1 := zfill(8, 31, %r0)
  *8* tmpb := m[tmp1]{8}
  *8* exp := exp | tmpb;

ORL_EXP_RI1 exp
  *32* tmp1 := zfill(8, 31, %r1)
  *8* tmpb := m[tmp1]{8}
  *8* exp := exp | tmpb;

ANL_EXP_RI0 exp
  *32* tmp1 := zfill(8, 31, %r0)
  *8* tmpb := m[tmp1]{8}
  *8* exp := exp & tmpb;

ANL_EXP_RI1 exp
  *32* tmp1 := zfill(8, 31, %r1)
  *8* tmpb := m[tmp1]{8}
  *8* exp := exp & tmpb;

XRL_EXP_RI0 exp
  *32* tmp1 := zfill(8, 31, %r0)
  *8* tmpb := m[tmp1]{8}
  *8* exp := exp ^ tmpb;

XRL_EXP_RI1 exp
  *32* tmp1 := zfill(8, 31, %r1)
  *8* tmpb := m[tmp1]{8}
  *8* exp := exp ^ tmpb;
## END ####

AJMP_IMM i32
  *32* %pc := i32;

ORL_DIR_A z32
  *8* m[z32] := %a | m[z32]{8};

ORL_DIR_IMM  z32, i32
  *8* m[z32] := m[z32]{8} | i32;

ORL_A_IMM i32
  *8* %a := %a | i32;

ORL_A_DIR  z32
  *8* %a := %a | m[z32]{8};

ORL_A_RI0
  *32* tmp1 := zfill(8, 31, %r0)
  *8* tmpb := m[tmp1]{8}
  *8* %a := %a | tmpb;

ORL_A_RI1
  *32* tmp1 := zfill(8, 31, %r1)
  *8* tmpb := m[tmp1]{8}
  *8* %a := %a | tmpb;

ORL_A_R0
  *8* %a := %a | %r0;

ORL_A_R1
  *8* %a := %a | %r1;

ORL_A_R2
  *8* %a := %a | %r2;

ORL_A_R3
  *8* %a := %a | %r3;

ORL_A_R4
  *8* %a := %a | %r4;

ORL_A_R5
  *8* %a := %a | %r5;

ORL_A_R6
  *8* %a := %a | %r6;

ORL_A_R7
  *8* %a := %a | %r7;

# 0x50

JNC_IMM exp
  #*32* %pc := %pc + 2
  #add_signed_pc(i32)
  #*32* %pc := [%CF = 0 ? tmp5 : %pc];
  *v* %flags := exp ~= 0 ;

# ACALL

ANL_DIR_A z32
  *8* m[z32] := %a & m[z32]{8};

ANL_DIR_IMM  z32, i32
  *8* m[z32] := m[z32]{8} & i32;

ANL_A_IMM i32
  *8* %a := %a & i32;

ANL_A_DIR  z32
  *8* %a := %a & m[z32]{8};

ANL_A_R0
  *8* %a := %a & %r0;

ANL_A_R1
  *8* %a := %a & %r1;

ANL_A_R2
  *8* %a := %a & %r2;

ANL_A_R3
  *8* %a := %a & %r3;

ANL_A_R4
  *8* %a := %a & %r4;

ANL_A_R5
  *8* %a := %a & %r5;

ANL_A_R6
  *8* %a := %a & %r6;

ANL_A_R7
  *8* %a := %a & %r7;

ANL_A_RI0
  *32* tmp1 := zfill(8, 31, %r0)
  *8* tmpb := m[tmp1]{8}
  *8* %a := %a & tmpb;

ANL_A_RI1
  *32* tmp1 := zfill(8, 31, %r1)
  *8* tmpb := m[tmp1]{8}
  *8* %a := %a & tmpb;

# 0x60

JZ_IMM exp
  #*32* %pc := %pc + 2
  #add_signed_pc(i32)
  #*32* %pc := [(%a = 0) ? tmp5 : %pc];
  *v* %flags := exp ~=0 ;
AJMP_IMM i32
  *32* %pc := i32;

XRL_DIR_A z32
  *8* %a := %a ^ m[z32]{8};

XRL_DIR_IMM  z32, i32
  *8* m[z32] := m[z32]{8} ^ i32;

XRL_A_IMM i32
  *8* %a := %a ^ i32;

XRL_A_DIR  z32
  *8* %a := %a ^ z32;

XRL_A_R0
  *8* %a := %a ^ %r0;

XRL_A_R1
  *8* %a := %a ^ %r1;

XRL_A_R2
  *8* %a := %a ^ %r2;

XRL_A_R3
  *8* %a := %a ^ %r3;

XRL_A_R4
  *8* %a := %a ^ %r4;

XRL_A_R5
  *8* %a := %a ^ %r5;

XRL_A_R6
  *8* %a := %a ^ %r6;

XRL_A_R7
  *8* %a := %a ^ %r7;

XRL_A_RI0
  *32* tmp1 := zfill(8, 31, %r0)
  *8* tmpb := m[tmp1]{8}
  *8* %a := %a ^ tmpb;

XRL_A_RI1
  *32* tmp1 := zfill(8, 31, %r1)
  *8* tmpb := m[tmp1]{8}
  *8* %a := %a ^ tmpb;


# 0x70

JNZ_IMM exp
  #*32* %pc := %pc + 2
  #add_signed_pc(i32)
  #*32* %pc := [(%a ~= 0) ? tmp5 : %pc];
  *v* %flags :=  exp = 0;

# ACALL
ORL_C_DIR  i32
  *1* %CF := m[i32]{1};

JMP_AADDDPTR 
  *32* tmp1 := zfill(16, 31, %dptr)
  *32* tmp2 := zfill(8, 31, %a)
  *32* %pc := tmp1 + tmp2;

MOV_DIR_IMM  z32, i32
  *8* m[z32] := i32;

MOV_A_IMM i32
  *8* %a := i32;

MOV_R0_IMM i32
  *8* r0 := i32;

MOV_R1_IMM i32
  *8* %r1 := i32;

MOV_R2_IMM i32
  *8* %r2 := i32;

MOV_R3_IMM i32
  *8* %r3 := i32;

MOV_R4_IMM i32
  *8* %r4 := i32;

MOV_R5_IMM i32
  *8* %r5 := i32;

MOV_R6_IMM i32
  *8* %r6 := i32;

MOV_R7_IMM i32
  *8* %r7 := i32;

MOV_RI0_IMM i32
  *32* tmp1 := zfill(8, 31, %r0)
  *8* m[tmp1] := i32;

MOV_RI1_IMM i32
  *32* tmp1 := zfill(8, 31, %r1)
  *8* m[tmp1] := i32;

MOV_RI0_EXP exp
  *32* tmp1 := zfill(8, 31, %r0)
  *8* m[tmp1] := exp;

MOV_RI1_EXP exp
  *32* tmp1 := zfill(8, 31, %r1)
  *8* m[tmp1] := exp;

# 0x80

SJMP_IMM i32
  *32* %pc := %pc + 2
  add_signed_pc(i32)
  *32* %pc := tmp5;

AJMP_IMM i32
  *32* %pc := i32;

ANL_C_DIR  z32
  *1* %CF := m[z32]{1};

MOVC_A_AaddPC
  *32* tmp1 := zfill(16, 31, %pc)
  *32* tmp2 := zfill(8, 31, %a)
  *32* tmp1 := tmp1 + tmp2
  *8* %a := m[tmp1]{8};

DIV_AB exp1, exp2
  *8* tmpb := exp1
  *8* exp1 := exp1 / exp2
  *8* exp2 := exp1 % exp2;

MOV_DIR_DIR  z32, rx32
  *8* m[z32] := m[rx32]{8};

MOV_DIR_RI0 exp1, exp2
  *32* tmp1 := zfill(8, 31, %r0)
  *8* exp1 := exp2;

MOV_DIR_RI1 exp1, exp2
  *32* tmp1 := zfill(8, 31, %r1)
  *8* exp1 := exp2;

MOV_DIR_R0 z32
  *8* m[z32] := %r0;

MOV_DIR_A z32
  *8* m[z32] := %a;

MOV_DIR_R1 z32
  *8* m[z32] := %r1;

MOV_DIR_R2 z32
  *8* m[z32] := %r2;

MOV_DIR_R3 z32
  *8* m[z32] := %r3;

MOV_DIR_R4 z32
  *8* m[z32] := %r4;

MOV_DIR_R5 z32
  *8* m[z32] := %r5;

MOV_DIR_R6 z32
  *8* m[z32] := %r6;

MOV_DIR_R7 z32
  *8* m[z32] := %r7;

# 0x90
MOV_DPTR_ADDR16 exp, i32
  *16* exp := i32;

# ACALL

MOV_DIR_C z32
  *1* m[z32] := %CF;

MOVC_A_AADDDPTR 
  *32* tmp1 := zfill(16, 31, %dptr)
  *32* tmp2 := zfill(8, 31, %a)
  *32* tmp1 := tmp1 + tmp2
  *8* %a := m[tmp1]{8};

SUBB_A_EXP exp1, exp2
  *8* exp1 := exp1 - exp2;
  
SUBB_A_IMM i32
  *8* %a := %a - i32;

SUBB_A_DIR  z32
  *8* %a := %a - m[z32]{8};

SUBB_A_R0
  *8* %a := %a - %r0;

SUBB_A_R1
  *8* %a := %a - %r1;

SUBB_A_R2
  *8* %a := %a - %r2;

SUBB_A_R3
  *8* %a := %a - %r3;

SUBB_A_R4
  *8* %a := %a - %r4;

SUBB_A_R5
  *8* %a := %a - %r5;

SUBB_A_R6
  *8* %a := %a - %r6;

SUBB_A_R7
  *8* %a := %a - %r7;

SUBB_A_RI0 exp
  *32* tmp1 := zfill(8, 31, %r0)
  *8* tmpb := m[tmp1]{8}
  *8* exp := exp - m[tmp1];

SUBB_A_RI1
  *32* tmp1 := zfill(8, 31, %r1)
  *8* tmpb := m[tmp1]{8}
  *8* exp := exp - m[tmp1];

# 0xA0

ORL_C_CDI z32
  *1* %CF :=  1 - m[z32]{1};

AJMP_IMM i32
  *32* %pc := i32;

MOV_C_DIR  z32
  *1* %CF := m[z32]{1};

INC_DPTR
  *16* %dptr := %dptr + 1;

MUL_AB exp1, exp2
  *16* m[%ab] := exp1 * exp2;

MOV_RI0_DIR  exp1, exp2
  *32* tmp1 := zfill(8, 31, %r0)
  *8*  exp1 := exp2;

MOV_REG_IMM z32, i32
  *8* z32 := i32;

MOV_RI1_DIR  exp1, exp2 
  *32* tmp1 := zfill(8, 31, %r1)
  *8* exp1 := exp2;

MOV_R0_DIR  z32
  *8* %r0 := m[z32]{8};

MOV_R1_DIR  z32
  *8* %r1 := m[z32]{8};

MOV_R2_DIR  z32
  *8* %r2 := m[z32]{8};

MOV_R3_DIR  z32
  *8* %r3 := m[z32]{8};

MOV_R4_DIR  z32
  *8* %r4 := m[z32]{8};

MOV_R5_DIR  z32
  *8* %r5 := m[z32]{8};

MOV_R6_DIR  z32
  *8* %r6 := m[z32]{8};

MOV_R7_DIR  z32
  *8* %r7 := m[z32]{8};


# 0xB0

ANL_C_CDI z32
  *1* %CF := 1 - m[z32]{1};

# ACALL

CPL_DIR  exp
  *1* exp := 1 - exp{1};

CPL_C
  *1* %CF := 1 - %CF;

CJNE_A_IMM_IMM i32, ix32
  *8* tmpb := i32@[0:7]
  *32* %pc := %pc + 3
  add_signed_pc(ix32)
  *32* %pc := [(%a = tmpb) ? %pc : tmp5]
  *1* %CF := [(%a < tmpb) ? 1 : 0];

CJNE_A_DIR_IMM  z32, i32
  *8* tmpb := z32
  *32* %pc := %pc + 3
  add_signed_pc(ix32)
  *32* %pc := [(%a = tmpb) ? %pc : tmp5]
  *1* %CF := [(%a < tmpb) ? 1 : 0];

# DEDO CJNE

CJNE_RI0 exp
  *32* tmp1 := zfill(8, 31, %r0)
  *v* %flags := m[tmp1] = exp;

CJNE_RI1 exp
  *32* tmp1 := zfill(8, 31, %r1)
  *v* %flags := m[tmp1] = exp;

CJNE_EXP exp1, exp2
  *v* %flags := exp1 = exp2;

# END CJNE

CJNE_RI0_IMM_IMM i32, ix32
  *32* tmp1 := zfill(8, 31, %r0)
  *8* tmpb := m[tmp1]{8}
  *32* %pc := %pc + 3
  add_signed_pc(ix32)
  *32* %pc := [(i32@[0:7] = tmpb) ? %pc : tmp5]
  *1* %CF := [(%a < tmpb) ? 1 : 0];

CJNE_RI1_IMM_IMM i32, ix32
  *32* tmp1 := zfill(8, 31, %r1)
  *8* tmpb := m[tmp1]{8}
  *32* %pc := %pc + 3
  add_signed_pc(ix32)
  *32* %pc := [(i32@[0:7] = tmpb) ? %pc : tmp5]
  *1* %CF := [(%a < tmpb) ? 1 : 0];

CJNE_R0_IMM_IMM i32, ix32
  *8* tmpb := i32@[0:7]
  *32* %pc := %pc + 3
  add_signed_pc(ix32)
  *32* %pc := [(%r0 = tmpb) ? %pc : tmp5]
  *1* %CF := [(%a < tmpb) ? 1 : 0];

CJNE_R1_IMM_IMM i32, ix32
  *8* tmpb := i32@[0:7]
  *32* %pc := %pc + 3
  add_signed_pc(ix32)
  *32* %pc := [(%r1 = tmpb) ? %pc : tmp5]
  *1* %CF := [(%a < tmpb) ? 1 : 0];

CJNE_R2_IMM_IMM i32, ix32
  *8* tmpb := i32@[0:7]
  *32* %pc := %pc + 3
  add_signed_pc(ix32)
  *32* %pc := [(%r2 = tmpb) ? %pc : tmp5]
  *1* %CF := [(%a < tmpb) ? 1 : 0];

CJNE_R3_IMM_IMM i32, ix32
  *8* tmpb := i32@[0:7]
  *32* %pc := %pc + 3
  add_signed_pc(ix32)
  *32* %pc := [(%r3 = tmpb) ? %pc : tmp5]
  *1* %CF := [(%a < tmpb) ? 1 : 0];

CJNE_R4_IMM_IMM i32, ix32
  *8* tmpb := i32@[0:7]
  *32* %pc := %pc + 3
  add_signed_pc(ix32)
  *32* %pc := [(%r4 = tmpb) ? %pc : tmp5]
  *1* %CF := [(%a < tmpb) ? 1 : 0];

CJNE_R5_IMM_IMM i32, ix32
  *8* tmpb := i32@[0:7]
  *32* %pc := %pc + 3
  add_signed_pc(ix32)
  *32* %pc := [(%r5 = tmpb) ? %pc : tmp5]
  *1* %CF := [(%a < tmpb) ? 1 : 0];

CJNE_R6_IMM_IMM i32, ix32
  *8* tmpb := i32@[0:7]
  *32* %pc := %pc + 3
  add_signed_pc(ix32)
  *32* %pc := [(%r6 = tmpb) ? %pc : tmp5]
  *1* %CF := [(%a < tmpb) ? 1 : 0];

CJNE_R7_IMM_IMM i32, ix32
  *8* tmpb := i32@[0:7]
  *32* %pc := %pc + 3
  add_signed_pc(ix32)
  *32* %pc := [(%r7 = tmpb) ? %pc : tmp5]
  *1* %CF := [(%a < tmpb) ? 1 : 0];


# 0xC0

PUSH_DIR z32
*32* %sp := %sp + 1
*32* m[%sp] := m[z32];

AJMP_IMM i32
  *32* %pc := i32;

CLR_DIR z32
  *8* z32 := 0;

#CLR_C
#  *1* %CF := 0;

SWAP_A exp
  *4* tmpb := exp@[0:3]
  *4* exp@[0:3] := exp@[4:7]
  *4* exp@[4:7] := tmpb;

#XCH_A_R0
#  *8* tmpb := %a
#  *8* %a := %r0
#  *8* %r0 := tmpb;

XCH_EXP exp1, exp2
  *8* tmpb := exp1
  *8* exp1 := exp2
  *8* exp2 := tmpb;

XCH_EXP_EXP exp1, exp2, exp3
  *8* tmpb := exp1
  *8* exp1 := exp2
  *8* exp3 := tmpb;  

XCH_A_R1
  *8* tmpb := %a
  *8* %a := %r1
  *8* %r1 := tmpb;

XCH_A_R2
  *8* tmpb := %a
  *8* %a := %r2
  *8* %r2 := tmpb;

XCH_A_R3
  *8* tmpb := %a
  *8* %a := %r3
  *8* %r3 := tmpb;

XCH_A_R4
  *8* tmpb := %a
  *8* %a := %r4
  *8* %r4 := tmpb;

XCH_A_R5
  *8* tmpb := %a
  *8* %a := %r5
  *8* %r5 := tmpb;

XCH_A_R6
  *8* tmpb := %a
  *8* %a := %r6
  *8* %r6 := tmpb;

XCH_A_R7
  *8* tmpb := %a
  *8* %a := %r7
  *8* %r7 := tmpb;

XCH_A_RI0 exp
  *32* tmp1 := zfill(8, 31, %r0)
  *8* tmpb := exp{8}
  *8* exp := m[tmp1] 
  *8* m[tmp1] := tmpb;

XCH_A_RI1 exp
  *32* tmp1 := zfill(8, 31, %r1)
  *8* tmpb := exp{8}
  *8* exp := m[tmp1] 
  *8* m[tmp1] := tmpb;

# 0xD0

POP_DIR  z32
*32* %sp := %sp - 1
*32* m[z32] := m[%sp];

# ACALL_addr11

SETB_DIR z32
  *8* z32 := 1 ;

#SETB_C
#  *1* %CF := 1;

#DA_A
#  *4* %a@[0:3] := [((%a@[0:3] > 9) | (%AC = 1)) ? %a@[0:3] + 6 : %a@[0:3]]
#  *4* %a@[4:7] := [((%a@[4:7] > 9) | (%CF = 1)) ? %a@[4:7] + 6 : %a@[4:7]];

DJNZ_DIR_IMM  z32, i32
  *32* %pc := %pc + 3
  *8* m[z32] := m[z32]{8} - 1
  add_signed_pc(i32)
  *32* %pc := [(m[z32]{8} = 0) ? %pc : tmp5];
DJNZ_EXP exp
  *8* exp := exp - 1
  *v* %flags := exp = 0;
  
DJNZ_EXP_LOOP exp
  *8* exp := exp - 1
  *v* %flags := exp ~= 0;

XCHD_A_RI0
  *32* tmp1 := zfill(8, 31, %r0)
  *8* tmpb := %a
  *8* %a := m[tmp1]{8}
  *8* m[tmp1] := tmpb;

XCHD_A_RI1
  *32* tmp1 := zfill(8, 31, %r1)
  *8* tmpb := %a
  *8* %a := m[tmp1]{8}
  *8* m[tmp1] := tmpb;

DJNZ_R0_IMM i32
  *32* %pc := %pc + 2
  *8* %r0 := %r0 - 1
  add_signed_pc(i32)
  *32* %pc := [(%r0 = 0) ? %pc : tmp5];

DJNZ_R1_IMM i32
  *32* %pc := %pc + 2
  *8* %r1 := %r1 - 1
  add_signed_pc(i32)
  *32* %pc := [(%r1 = 0) ? %pc : tmp5];

DJNZ_R2_IMM i32
  *32* %pc := %pc + 2
  *8* %r2 := %r2 - 1
  add_signed_pc(i32)
  *32* %pc := [(%r2 = 0) ? %pc : tmp5];

DJNZ_R3_IMM i32
  *32* %pc := %pc + 2
  *8* %r3 := %r3 - 1
  add_signed_pc(i32)
  *32* %pc := [(%r3 = 0) ? %pc : tmp5];

DJNZ_R4_IMM i32
  *32* %pc := %pc + 2
  *8* %r4 := %r4 - 1
  add_signed_pc(i32)
  *32* %pc := [(%r4 = 0) ? %pc : tmp5];

DJNZ_R5_IMM i32
  *32* %pc := %pc + 2
  *8* %r5 := %r5 - 1
  add_signed_pc(i32)
  *32* %pc := [(%r5 = 0) ? %pc : tmp5];

DJNZ_R6_IMM i32
  *32* %pc := %pc + 2
  *8* %r6 := %r6 - 1
  add_signed_pc(i32)
  *32* %pc := [(%r6 = 0) ? %pc : tmp5];

DJNZ_R7_IMM i32
  *32* %pc := %pc + 2
  *8* %r7 := %r7 - 1
  add_signed_pc(i32)
  *32* %pc := [(%r7 = 0) ? %pc : tmp5];

# 0xE0

MOVX_A_DPTRA exp1, exp2
  *32* tmp1 := zfill(16, 31, %dptr)
  *8* exp1 := exp2{8};

MOVX_A_RI0 exp1, exp2
  *32* tmp1 := zfill(8, 31, %r0)
  *8* exp1 := exp2;

MOVX_A_RI1 exp1, exp2
  *32* tmp1 := zfill(8, 31, %r1)
  *8* exp1 := exp2;

CLR_A
  *8* %a := 0;

MOV_A_EXP z32
  *8* %a := z32;

MOV_EXP exp1, exp2
  *8* exp1 := exp2;

MOV_A_DIR  z32
  *8* %a := m[z32]{8};

MOV_A_R0
  *8* %a := %r0;

MOV_A_R1
  *8* %a := %r1;

MOV_A_R2
  *8* %a := %r2;

MOV_A_R3
  *8* %a := %r3;

MOV_A_R4
  *8* %a := %r4;

MOV_A_R5
  *8* %a := %r5;

MOV_A_R6
  *8* %a := %r6;

MOV_A_R7
  *8* %a := %r7;

MOV_A_RI0 exp1, exp2
  *32* tmp1 := zfill(8, 31, %r0)
  *8* exp1 := exp2;

MOV_A_RI1 exp1, exp2
  *32* tmp1 := zfill(8, 31, %r1)
  *8* exp1 := exp2;


# 0xF0

MOVX_DPTRA_A exp
  *32* tmp1 := zfill(16, 31, %dptr)
  *8* m[tmp1] := exp;

# ACALL

MOVX_RI0_A exp
  *32* tmp1 := zfill(8, 31, %r0)
  *8* m[tmp1] := exp;

MOVX_RI1_A exp
  *32* tmp1 := zfill(8, 31, %r1)
  *8* m[tmp1] := exp;

CPL_A exp
  *8* exp := 0 - exp;
CPL_BIT exp
  *8* exp :=  1 - exp@[0:7];

MOV_RI0_A exp
  *32* tmp1 := zfill(8, 31, %r0)
  *8* m[tmp1] := exp;

MOV_RI1_A exp
  *32* tmp1 := zfill(8, 31, %r1)
  *8* m[tmp1] := exp;

MOV_R0_A
  *8* %r0 := %a;

MOV_R1_A
  *8* %r1 := %a;

MOV_R2_A
  *8* %r2 := %a;

MOV_R3_A
  *8* %r3 := %a;

MOV_R4_A
  *8* %r4 := %a;

MOV_R5_A
  *8* %r5 := %a;

MOV_R6_A
  *8* %r6 := %a;

MOV_R7_A
  *8* %r7 := %a;

ADDFLAG(op1, op2, result) {
  *1* %CF := 1
  *1* %AC := 1
  *1* %OV := 1
};

SUBFLAG(op1, op2, result) {
  *1* %CF := 1
  *1* %AC := 1
  *1* %OV := 1  
};